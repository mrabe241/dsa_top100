# ============================
# .env (shared configuration)
# ============================

# ============================
# config.py (shared loader)
# ============================
import os
from dotenv import load_dotenv
# Load environment variables from .env
load_dotenv()
class Config:
 OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
 NEO4J_URI = os.getenv("NEO4J_URI")
 NEO4J_USER = os.getenv("NEO4J_USER")
 NEO4J_PASS = os.getenv("NEO4J_PASS")
 @staticmethod
 def validate():
 missing = []
 for key, value in Config.__dict__.items():
 if key.isupper() and value is None:
 missing.append(key)
 if missing:
 raise ValueError(f"
❌
 Missing required environment variables: {', '.join(missing)}")
# ============================
# parser_server.py (MCP Server)
# ============================
import os
import asyncio
import requests
from openai import AsyncOpenAI
from mcp.server.fastmcp import FastMCP
from config import Config
# Validate environment variables
Config.validate()
client = AsyncOpenAI(api_key=Config.OPENAI_API_KEY)
mcp = FastMCP("ResumeService")
RESUME_FOLDER = "resumes"
SYSTEM_CONTEXT = "You are a resume parsing engine that generates Neo4j Cypher queries."
TASK_CONTEXT = """
Extract candidate data and relationships following this schema:
(:Person {name, email, phone})
 -[:HAS_SKILL]->(:Skill {name})
 -[:WORKED_ON]->(:Project {title, description})
 -[:HAS_EDUCATION]->(:Education {degree, university, year})
 -[:WORKED_AT]->(:Experience {company, role, duration})
(:Project)-[:USED_SKILL]->(:Skill)
"""
RULES = """
- Always use MERGE to avoid duplicates.
- Output ONLY Cypher queries, one per line.
"""
async def parse_resume_to_cypher(text: str, model: str = "gpt-4o-mini") -> str:
 final_prompt = f"""
 {SYSTEM_CONTEXT}
 {TASK_CONTEXT}
 {RULES}
 Resume:
 {text}
 """
 response = await client.chat.completions.create(
 model=model,
 messages=[
 {"role": "system", "content": "You are a Neo4j Cypher generator."},
 {"role": "user", "content": final_prompt}
 ]
 )
 return response.choices[0].message.content.strip()
async def _commit_to_neo4j(cypher_queries: str) -> dict:
 payload = {"statements": [{"statement": q.strip()} for q in cypher_queries.split("\n") if q.strip()]}
 loop = asyncio.get_event_loop()
 return await loop.run_in_executor(
 None,
 lambda: requests.post(
 Config.NEO4J_URI,
 auth=(Config.NEO4J_USER, Config.NEO4J_PASS),
 json=payload,
 headers={"Content-Type": "application/json"}
 ).json()
 )
async def process_resume(filename: str, text: str):
 cypher = await parse_resume_to_cypher(text)
 result = await _commit_to_neo4j(cypher)
 return {"file": filename, "cypher": cypher, "result": result}
# MCP Tools
@mcp.tool()
async def ingest_resumes() -> dict:
 if not os.path.exists(RESUME_FOLDER):
 return {"error": f"Folder '{RESUME_FOLDER}' not found."}
 tasks = []
 for file in os.listdir(RESUME_FOLDER):
 if file.endswith(".txt"):
 with open(os.path.join(RESUME_FOLDER, file), "r", encoding="utf-8") as f:
 resume_text = f.read()
 tasks.append(process_resume(file, resume_text))
 results = await asyncio.gather(*tasks)
 return {"ingested": results}
@mcp.tool()
async def ingest_one_resume(text: str, filename: str = "uploaded_resume.txt") -> dict:
 return await process_resume(filename, text)
@mcp.tool()
async def commit_to_neo4j(cypher_queries: str) -> dict:
 return await _commit_to_neo4j(cypher_queries)
@mcp.tool()
async def search_candidate(prompt: str, model: str = "gpt-4o-mini") -> dict:
 schema_context = """
 Graph Schema:
 (:Person {name, email, phone})
 -[:HAS_SKILL]->(:Skill {name})
 -[:WORKED_ON]->(:Project {title, description})
 -[:HAS_EDUCATION]->(:Education {degree, university, year})
 -[:WORKED_AT]->(:Experience {company, role, duration})
 (:Project)-[:USED_SKILL]->(:Skill)
 Rules:
 - Always use Cypher 5 syntax.
 - Only return Cypher queries, no explanations.
 """
 final_prompt = f"""
 You are a Cypher query generator for Neo4j.
 Schema:
 {schema_context}
 User request: {prompt}
 """
 response = await client.chat.completions.create(
 model=model,
 messages=[
 {"role": "system", "content": "You are a Neo4j Cypher generator."},
 {"role": "user", "content": final_prompt}
 ]
 )
 cypher_query = response.choices[0].message.content.strip()
 result = await _commit_to_neo4j(cypher_query)
 return {"cypher": cypher_query, "neo4j_response": result}
if __name__ == "__main__":
 print("
 ResumeService MCP server running (stdio transport)")
 mcp.run()
# ============================
# app.py (Streamlit UI)
# ============================
import asyncio
import streamlit as st
from mcp.client import Client
from config import Config
Config.validate()
def run_async(coro):
 return asyncio.get_event_loop().run_until_complete(coro)
async def run_search(prompt: str):
 client = Client("ResumeService")
 await client.start(["python", "parser_server.py"])
 result = await client.call_tool("search_candidate", {"prompt": prompt})
 await client.stop()
 return result
st.set_page_config(page_title="Resume Search", layout="wide")
st.title("
 Resume Search with Neo4j + MCP")
prompt = st.text_input("Ask your question (e.g., 'Find candidates with Python and NLP')")
if st.button("Search"):
 result = run_async(run_search(prompt))
 st.text_area("Generated Cypher Query", result["cypher"], height=200)
 st.json(result["neo4j_response"])
# ============================
# agent.py (Standalone Agent)
# ============================
import asyncio
from mcp.client import Client
from config import Config
Config.validate()
async def main():
 client = Client("ResumeService")
 await client.start(["python", "parser_server.py"])
 ingest_result = await client.call_tool("ingest_resumes", {})
 print("=== Ingest Resumes ===")
 print(ingest_result)
 single_result = await client.call_tool("ingest_one_resume", {
 "text": "Jane Doe, Email: jane@example.com, Skills: Python, React",
 "filename": "resume_jane.txt"
 })
 print("=== Ingest One Resume ===")
 print(single_result)
 search_result = await client.call_tool("search_candidate", {
 "prompt": "Find candidates with Python"
 })
 print("=== Search Result ===")
 print(search_result)
 await client.stop()
if __name__ == "__main__":
 asyncio.run(main())
