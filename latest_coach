import json
import re
from difflib import SequenceMatcher

# ---------- config ----------
BASE_FROM = 3111            # original series start
BASE_TO   = 4000            # new series start
SIM_THRESHOLD = 1.0         # 1.0 = require 100% similarity (after normalization). Try 0.97 for fuzzy.

PAT_ABC = re.compile(r"^ABC-(\d+)$")

# ---------- helpers ----------
def normalize(s: str) -> str:
    """Lowercase and remove all non-alphanumeric chars for robust comparison."""
    return re.sub(r'[^a-z0-9]', '', (s or '').lower())

def similar(a: str, b: str) -> float:
    """Similarity ratio of two strings (0..1) using difflib."""
    return SequenceMatcher(None, a, b).ratio()

def remap_abc(s: str) -> str:
    """Shift ABC-<n> where n>=3111 so that 3111->4000, 3112->4001, etc.
       Keeps original digit width (zero-pads to same length)."""
    m = PAT_ABC.match(s or "")
    if not m:
        return s
    digits = m.group(1)
    n = int(digits)
    if n < BASE_FROM:
        return s
    new_n = BASE_TO + (n - BASE_FROM)
    return f"ABC-{str(new_n).zfill(len(digits))}"

def walk_remap(obj):
    """Recursively remap ABC codes across dicts/lists/strings."""
    if isinstance(obj, dict):
        return {k: walk_remap(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [walk_remap(v) for v in obj]
    if isinstance(obj, str):
        return remap_abc(obj)
    return obj

def dedup_by_similarity(items, threshold=SIM_THRESHOLD):
    """
    Remove duplicates where (key + Desc) are 'threshold'-similar after normalization.
    Keeps first occurrence; preserves order.
    """
    kept = []
    signatures = []  # store normalized composite strings for similarity checks
    for it in items:
        if not isinstance(it, dict):
            # keep non-dict items as-is
            kept.append(it)
            continue
        k = normalize(str(it.get("key", "")))
        d = normalize(str(it.get("Desc", "")))
        comp = f"{k}|{d}"

        # compare to all kept signatures
        is_dup = any(similar(comp, prev) >= threshold for prev in signatures)
        if is_dup:
            continue
        signatures.append(comp)
        kept.append(it)
    return kept

# ---------- main ----------
with open("data.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# 1) Dedupe only when the top-level is a list of objects or { "data": [...] }
if isinstance(data, list):
    data = dedup_by_similarity(data, SIM_THRESHOLD)
elif isinstance(data, dict) and isinstance(data.get("data"), list):
    data["data"] = dedup_by_similarity(data["data"], SIM_THRESHOLD)

# 2) Remap ABC codes everywhere
updated = walk_remap(data)

with open("data_updated.json", "w", encoding="utf-8") as f:
    json.dump(updated, f, indent=2, ensure_ascii=False)
