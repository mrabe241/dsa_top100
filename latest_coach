import json
import re
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# ----- config -----
BASE_FROM = 3111
BASE_TO   = 4000
SIM_THRESHOLD = 0.95   # adjust (0.9 ~ fuzzy, 1.0 = only exact embeddings)

PAT_ABC = re.compile(r"^ABC-(\d+)$")

# Load embedding model (lightweight multilingual model)
model = SentenceTransformer("all-MiniLM-L6-v2")

def remap_abc(s: str) -> str:
    """Shift ABC-<n> where n>=3111 so that 3111->4000, 3112->4001, etc."""
    m = PAT_ABC.match(s or "")
    if not m:
        return s
    digits = m.group(1)
    n = int(digits)
    if n < BASE_FROM:
        return s
    new_n = BASE_TO + (n - BASE_FROM)
    return f"ABC-{str(new_n).zfill(len(digits))}"

def walk_remap(obj):
    """Recursively walk and remap ABC codes."""
    if isinstance(obj, dict):
        return {k: walk_remap(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [walk_remap(v) for v in obj]
    if isinstance(obj, str):
        return remap_abc(obj)
    return obj

def dedup_by_embeddings(items, threshold=SIM_THRESHOLD):
    """
    Deduplicate based on semantic similarity of (key + Desc) using embeddings.
    Keeps the first item; drops subsequent ones if similarity >= threshold.
    """
    kept = []
    kept_embs = []

    for it in items:
        if not isinstance(it, dict):
            kept.append(it)
            continue

        comp = f"{it.get('key','')} | {it.get('Desc','')}"
        emb = model.encode([comp], normalize_embeddings=True)

        is_dup = False
        if kept_embs:
            sims = cosine_similarity(emb, np.vstack(kept_embs))[0]
            if sims.max() >= threshold:
                is_dup = True

        if not is_dup:
            kept.append(it)
            kept_embs.append(emb[0])

    return kept

# ----- load -----
with open("data.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# ----- dedup -----
if isinstance(data, list):
    data = dedup_by_embeddings(data)
elif isinstance(data, dict) and isinstance(data.get("data"), list):
    data["data"] = dedup_by_embeddings(data["data"])

# ----- remap ABC codes -----
updated = walk_remap(data)

# ----- save -----
with open("data_updated.json", "w", encoding="utf-8") as f:
    json.dump(updated, f, indent=2, ensure_ascii=False)
